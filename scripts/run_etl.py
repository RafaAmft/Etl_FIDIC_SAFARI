"""
Script principal de execu√ß√£o do ETL FIDC.

Executa o pipeline completo: ETL ‚Üí Valida√ß√µes ‚Üí Relat√≥rios

Autor: Rafael Augusto
Data: Janeiro 2026
"""

import sys
import os
from pathlib import Path
import pandas as pd
import logging

# Adicionar src ao path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.services.etl_service import FIDCETLService
from src.services.qa_service import QAService
from src.utils.logging_config import setup_logging
from src.config import settings


def main():
    """Executa o pipeline ETL completo."""
    
    # Configurar logging
    log_file = settings.OUTPUTS_DIR / "etl_fidc.log"
    setup_logging(log_level="INFO", log_file=str(log_file))
    logger = logging.getLogger(__name__)
    
    print("=" * 80)
    print("üöÄ ETL FIDC - Pipeline Completo")
    print("=" * 80)
    print()
    
    # Verificar arquivo de entrada
    arquivo_entrada = settings.DATA_DIR / "lista_cnpjs_fidc.csv"
    
    if not arquivo_entrada.exists():
        logger.error(f"Arquivo n√£o encontrado: {arquivo_entrada}")
        print(f"\n‚ùå ERRO: Arquivo '{arquivo_entrada}' n√£o encontrado!")
        print(f"\nColoque o arquivo CSV com os CNPJs em: {settings.DATA_DIR}")
        return 1
    
    try:
        # 1. Carregar CNPJs
        logger.info(f"Carregando CNPJs de {arquivo_entrada}")
        df_cnpjs = pd.read_csv(arquivo_entrada)
        
        if 'CNPJ' not in df_cnpjs.columns:
            logger.error("Coluna 'CNPJ' n√£o encontrada no CSV")
            print("\n‚ùå ERRO: CSV deve conter coluna 'CNPJ'")
            return 1
        
        # Converter para string e preencher com zeros
        cnpjs = df_cnpjs['CNPJ'].astype(str).str.replace('.0', '', regex=False).str.zfill(14).tolist()
        
        logger.info(f"Total de CNPJs carregados: {len(cnpjs)}")
        print(f"‚úÖ {len(cnpjs)} CNPJs carregados")
        print(f"‚è±Ô∏è  Tempo estimado: ~{len(cnpjs) * settings.DELAY_ENTRE_REQUISICOES / 60:.1f} minutos\n")
        
        # 2. Executar ETL completo
        etl_service = FIDCETLService()
        logger.info("Iniciando pipeline ETL...")
        
        df_resultado = etl_service.process_and_validate(cnpjs, show_progress=True)
        
        # 3. Executar QA e gerar relat√≥rios
        qa_service = QAService()
        logger.info("Executando pipeline de QA...")
        
        results = qa_service.full_qa_pipeline(df_resultado, str(settings.OUTPUTS_DIR))
        
        # 4. Resumo final
        print("\n" + "=" * 80)
        print("‚úÖ ETL CONCLU√çDO COM SUCESSO!")
        print("=" * 80)
        print(f"\nüìä Estat√≠sticas:")
        print(f"   Total processado: {len(df_resultado):,}")
        print(f"   Sucesso: {(df_resultado['STATUS'] == 'SUCESSO').sum():,}")
        print(f"   Erros: {(df_resultado['STATUS'] != 'SUCESSO').sum():,}")
        
        print(f"\nüìÅ Arquivos gerados em: {settings.OUTPUTS_DIR}")
        print(f"   ‚úÖ cleaned_snapshot_YYYYMMDD_HHMMSS.csv - Dados completos validados (datado)")
        print(f"   ‚ö†Ô∏è  qa_issues.csv - Registros com issues de qualidade")
        print(f"   üìù etl_fidc.log - Log detalhado da execu√ß√£o")
        
        logger.info("Pipeline conclu√≠do com sucesso!")
        return 0
        
    except Exception as e:
        logger.exception("Erro fatal durante execu√ß√£o do ETL")
        print(f"\n‚ùå ERRO FATAL: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
